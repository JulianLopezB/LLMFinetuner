{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "colab-badge",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/your-repo/your-notebook.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-packages",
   "metadata": {},
   "source": [
    "## Install Necessary Packages\n",
    "First, we need to install the required packages for our fine-tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-environment",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/JulianLopezB/LLMFinetuner.git\n",
    "!pip install transformers datasets torch accelerate huggingface_hub scipy peft bitsandbytes python-dotenv hydra-core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-libraries",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries\n",
    "Next, we import all the necessary libraries and modules that we will use throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "setup-env",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhydra\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01momegaconf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DictConfig, OmegaConf\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_setup\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelSetup\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CustomTrainer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from src.data_loader import DataLoader\n",
    "from src.model_setup import ModelSetup\n",
    "from src.trainer import CustomTrainer\n",
    "from src.evaluator import Evaluator\n",
    "from src.huggingface_integration import HuggingFaceIntegration\n",
    "from src.config import Config\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "check-environment",
   "metadata": {},
   "source": [
    "## Check Environment\n",
    "Ensure that CUDA is available and the necessary environment variables are set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check-env",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for CUDA availability\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"CUDA is not available. Please check your installation of CUDA and NVIDIA drivers.\")\n",
    "\n",
    "# Check for HUGGINGFACE_TOKEN environment variable\n",
    "if 'HUGGINGFACE_TOKEN' not in os.environ:\n",
    "    raise EnvironmentError(\"HUGGINGFACE_TOKEN is not set. Please set this environment variable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-config",
   "metadata": {},
   "source": [
    "## Load Configuration\n",
    "Load the configuration file using Hydra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-config-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the configuration path and name\n",
    "config_path = './config'\n",
    "config_name = 'finetuning_config'\n",
    "\n",
    "# Load the configuration\n",
    "config = OmegaConf.load(os.path.join(config_path, f'{config_name}.yaml'))\n",
    "print(OmegaConf.to_yaml(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-dataset",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "Load the dataset using the `DataLoader` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-dataset-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_loader = DataLoader(config.dataset.path, from_huggingface=config.dataset.from_huggingface)\n",
    "train_dataset, eval_dataset = data_loader.get_dataset()['train'].train_test_split(test_size=0.2).values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-model",
   "metadata": {},
   "source": [
    "## Setup Model and Tokenizer\n",
    "Setup the model and tokenizer with quantization and device configuration if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-model-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the model and tokenizer\n",
    "model_setup = ModelSetup(\n",
    "    config.model.name,\n",
    "    quantization_config=config.model.quantization,\n",
    "    device_map=config.model.device_map\n",
    ")\n",
    "model, tokenizer = model_setup.get_model_and_tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configure-peft",
   "metadata": {},
   "source": [
    "## Configure PEFT\n",
    "Configure PEFT (Parameter-Efficient Fine-Tuning) if enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configure-peft-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure PEFT if enabled\n",
    "if config.training.peft_enabled:\n",
    "    lora_config = config.training.lora_config\n",
    "else:\n",
    "    lora_config = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-trainer",
   "metadata": {},
   "source": [
    "## Setup and Run Trainer\n",
    "Setup the `CustomTrainer` and start the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-trainer-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and run the trainer\n",
    "trainer = CustomTrainer(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    train_dataset,\n",
    "    eval_dataset,\n",
    "    config.training.output_dir,\n",
    "    peft_config=lora_config,\n",
    "    **config.training.trainer_args\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluate-model",
   "metadata": {},
   "source": [
    "## Evaluate Model\n",
    "Evaluate the model on the evaluation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluate-model-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "evaluator = Evaluator(model, tokenizer, eval_dataset)\n",
    "results = evaluator.evaluate()\n",
    "print(\"Evaluation Results:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "push-model",
   "metadata": {},
   "source": [
    "## Push Model to Hugging Face\n",
    "If enabled, save and push the model to Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "push-model-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If Hugging Face push is enabled\n",
    "if config.training.hf_push:\n",
    "    hf_integration = HuggingFaceIntegration(\n",
    "        model,\n",
    "        config.model.name,\n",
    "        config.model.new_model,\n",
    "        config.training.hf_org\n",
    "    )\n",
    "    hf_integration.save_and_push_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "main-function",
   "metadata": {},
   "source": [
    "## Main Function\n",
    "Define the main function to run the entire fine-tuning pipeline using Hydra for configuration management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main-function-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "@hydra.main(version_base=None, config_path=config_path, config_name=config_name)\n",
    "def main(config: DictConfig):\n",
    "    # Load the dataset\n",
    "    data_loader = DataLoader(config.dataset.path, from_huggingface=config.dataset.from_huggingface)\n",
    "    train_dataset, eval_dataset = data_loader.get_dataset()['train'].train_test_split(test_size=0.2).values()\n",
    "\n",
    "    # Setup the model and tokenizer with quantization and device configuration if required\n",
    "    model_setup = ModelSetup(\n",
    "        config.model.name,\n",
    "        quantization_config=config.model.quantization,\n",
    "        device_map=config.model.device_map\n",
    "    )\n",
    "    model, tokenizer = model_setup.get_model_and_tokenizer()\n",
    "\n",
    "    # Configure PEFT if enabled\n",
    "    if config.training.peft_enabled:\n",
    "        lora_config = config.training.lora_config\n",
    "    else:\n",
    "        lora_config = None\n",
    "\n",
    "    # Setup and run the trainer\n",
    "    trainer = CustomTrainer(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        train_dataset,\n",
    "        eval_dataset,\n",
    "        config.training.output_dir,\n",
    "        peft_config=lora_config,\n",
    "        **config.training.trainer_args\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model\n",
    "    evaluator = Evaluator(model, tokenizer, eval_dataset)\n",
    "    results = evaluator.evaluate()\n",
    "    print(\"Evaluation Results:\", results)\n",
    "\n",
    "    # If Hugging Face push is enabled\n",
    "    if config.training.hf_push:\n",
    "        hf_integration = HuggingFaceIntegration(\n",
    "            model,\n",
    "            config.model.name,\n",
    "            config.model.new_model,\n",
    "            config.training.hf_org\n",
    "        )\n",
    "        hf_integration.save_and_push_model()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
